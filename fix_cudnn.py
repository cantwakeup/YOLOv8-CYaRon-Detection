#!/usr/bin/env python3
"""
CUDNNé—®é¢˜è¯Šæ–­å’Œä¿®å¤è„šæœ¬
"""
import os
import torch
import subprocess

def check_environment():
    """æ£€æŸ¥å½“å‰ç¯å¢ƒ"""
    print("=== ç¯å¢ƒæ£€æŸ¥ ===")
    print(f"Python: {os.sys.version}")
    print(f"PyTorch: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA version: {torch.version.cuda}")
        print(f"CUDNN version: {torch.backends.cudnn.version()}")
        print(f"GPU count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")

def test_cudnn():
    """æµ‹è¯•CUDNNæ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("\n=== CUDNNæµ‹è¯• ===")
    try:
        # åˆ›å»ºç®€å•çš„å·ç§¯æ“ä½œæµ‹è¯•CUDNN
        x = torch.randn(1, 3, 224, 224).cuda()
        conv = torch.nn.Conv2d(3, 64, 3, padding=1).cuda()
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            y = conv(x)
        print("âœ“ CUDNNå‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•åå‘ä¼ æ’­
        y.sum().backward()
        print("âœ“ CUDNNåå‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
        
        return True
    except Exception as e:
        print(f"âŒ CUDNNæµ‹è¯•å¤±è´¥: {e}")
        return False

def fix_cudnn_env():
    """è®¾ç½®CUDNNç¯å¢ƒå˜é‡"""
    print("\n=== ä¿®å¤CUDNNç¯å¢ƒ ===")
    
    # ç¦ç”¨CUDNNçš„ä¸€äº›ä¼˜åŒ–é€‰é¡¹
    os.environ['CUDNN_DETERMINISTIC'] = '1'
    os.environ['CUDNN_BENCHMARK'] = '0'
    
    # ç¦ç”¨CUDNNå¼•æ“é¢„ç¼–è¯‘
    os.environ['TORCH_CUDNN_V8_API_DISABLED'] = '1'
    
    print("âœ“ è®¾ç½®ç¯å¢ƒå˜é‡:")
    print("  CUDNN_DETERMINISTIC=1")
    print("  CUDNN_BENCHMARK=0") 
    print("  TORCH_CUDNN_V8_API_DISABLED=1")

def suggest_solutions():
    """å»ºè®®è§£å†³æ–¹æ¡ˆ"""
    print("\n=== è§£å†³æ–¹æ¡ˆå»ºè®® ===")
    print("1. ç¯å¢ƒå˜é‡æ–¹æ¡ˆï¼ˆå·²åº”ç”¨ï¼‰:")
    print("   export TORCH_CUDNN_V8_API_DISABLED=1")
    print("   export CUDNN_DETERMINISTIC=1")
    
    print("\n2. é‡è£…PyTorchï¼ˆæ¨èï¼‰:")
    print("   pip uninstall torch torchvision")
    print("   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121")
    
    print("\n3. é™çº§åˆ°CPUè®­ç»ƒ:")
    print("   åœ¨è®­ç»ƒä»£ç ä¸­è®¾ç½® device='cpu'")
    
    print("\n4. ä½¿ç”¨ä¸åŒçš„CUDAç‰ˆæœ¬:")
    print("   conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia")

if __name__ == "__main__":
    print("CUDNNé—®é¢˜è¯Šæ–­å’Œä¿®å¤å·¥å…·")
    print("=" * 50)
    
    check_environment()
    fix_cudnn_env()
    
    # é‡æ–°æµ‹è¯•
    if test_cudnn():
        print("\nğŸ‰ CUDNNé—®é¢˜å·²è§£å†³ï¼å¯ä»¥ç»§ç»­è®­ç»ƒã€‚")
    else:
        print("\nâš ï¸  CUDNNé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·å°è¯•å…¶ä»–è§£å†³æ–¹æ¡ˆã€‚")
        suggest_solutions()
